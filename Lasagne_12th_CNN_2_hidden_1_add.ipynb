{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lasagne code try and edit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## input our data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import scipy.linalg as sp\n",
      "from sklearn.datasets import load_svmlight_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_train, y = load_svmlight_file(\"./phase1/new/aug_train_50_big.dat\")\n",
      "# print type(xx_train)\n",
      "print xx_train.shape\n",
      "xx_train = np.array(xx_train.todense()).reshape(-1,)\n",
      "# xx_train = xx_train.dtype(np.float32)\n",
      "xx_train = np.float32(xx_train)\n",
      "xx_train = xx_train.reshape(24696,2500)\n",
      "# print xx_train.shape\n",
      "print type(xx_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 2500)\n",
        "<type 'numpy.ndarray'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sizee = 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pylab.ion()\n",
      "# pylab.imshow(xxxx[0],cmap=cm.gray)\n",
      "x = xx_train.reshape(24696,sizee**2)\n",
      "x = x.astype(np.float32)\n",
      "\n",
      "print x.shape\n",
      "print type(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 2500)\n",
        "<type 'numpy.ndarray'>\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def one_hot(x,n):\n",
      "    if type(x) == list:\n",
      "            x = np.array(x)\n",
      "    x = x.flatten()\n",
      "    o_h = np.zeros((len(x),n))\n",
      "    o_h[np.arange(len(x)),x] = 1\n",
      "    return o_h\n",
      "\n",
      "y = y.astype(int32)    \n",
      "y = one_hot(y, 32)\n",
      "y = y.astype(np.float32)\n",
      "\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 32)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## split data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation as cv\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search as gs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cv.train_test_split(x, y, test_size=0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## First model of Lasagne with single hidden layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add to kfkd.py\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "\n",
      "net1 = NeuralNet(\n",
      "    layers=[  # three layers: one hidden layer\n",
      "        ('input', layers.InputLayer),\n",
      "        ('hidden', layers.DenseLayer),\n",
      "        ('output', layers.DenseLayer),\n",
      "        ],\n",
      "    # layer parameters:\n",
      "    input_shape=(128, 2500),  # 128 images per batch times 100x100 input pixels\n",
      "    hidden_num_units=300,  # number of units in hidden layer\n",
      "    output_nonlinearity=None,  # output layer uses identity function\n",
      "    output_num_units=32,  # 30 target values\n",
      "\n",
      "    # optimization method:\n",
      "    upate=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "    update_momentum=0.9,\n",
      "\n",
      "    # regression=False,  # flag to indicate we're dealing with regression problem\n",
      "    regression=True,  # flag to indicate we're dealing with regression problem\n",
      "    max_epochs=1000,  # we want to train this many epochs\n",
      "    verbose=1,\n",
      "    )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GRID K520\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time net1.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss = np.array([i[\"train_loss\"] for i in net1.train_history_])\n",
      "valid_loss = np.array([i[\"valid_loss\"] for i in net1.train_history_])\n",
      "pyplot.plot(train_loss, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(2.5e-2, 0.32e-1)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "\n",
      "# overfit result, should use validation result\n",
      "y_pred = net1.predict(X_test)\n",
      "# print y_pred[1]\n",
      "# np.argmax(y_pred[i]),np.argmax(y[i])\n",
      "y_pred = np.array(map((lambda x: np.argmax(x)), y_pred))\n",
      "yyy = np.array(map((lambda x: np.argmax(x)), y_test))\n",
      "\n",
      "print metrics.classification_report((yyy), (y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## NET 6 in the rock"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "\n",
      "def float32(k):\n",
      "    return np.cast['float32'](k)\n",
      "\n",
      "class AdjustVariable(object):\n",
      "    def __init__(self, name, start=0.03, stop=0.001):\n",
      "        self.name = name\n",
      "        self.start, self.stop = start, stop\n",
      "        self.ls = None\n",
      "\n",
      "    def __call__(self, nn, train_history):\n",
      "        if self.ls is None:\n",
      "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
      "\n",
      "        epoch = train_history[-1]['epoch']\n",
      "        new_value = float32(self.ls[epoch - 1])\n",
      "        getattr(nn, self.name).set_value(new_value)\n",
      "\n",
      "class EarlyStopping(object):\n",
      "    def __init__(self, patience=100):\n",
      "        self.patience = patience\n",
      "        self.best_valid = np.inf\n",
      "        self.best_valid_epoch = 0\n",
      "        self.best_weights = None\n",
      "\n",
      "    def __call__(self, nn, train_history):\n",
      "        current_valid = train_history[-1]['valid_loss']\n",
      "        current_epoch = train_history[-1]['epoch']\n",
      "        if current_valid < self.best_valid:\n",
      "            self.best_valid = current_valid\n",
      "            self.best_valid_epoch = current_epoch\n",
      "            self.best_weights = [w.get_value() for w in nn.get_all_params()]\n",
      "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
      "            print(\"Early stopping.\")\n",
      "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
      "                self.best_valid, self.best_valid_epoch))\n",
      "            nn.load_weights_from(self.best_weights)\n",
      "            raise StopIteration()\n",
      "        \n",
      "# use the cuda-convnet implementations of conv and max-pool layer\n",
      "Conv2DLayer = layers.cuda_convnet.Conv2DCCLayer\n",
      "MaxPool2DLayer = layers.cuda_convnet.MaxPool2DCCLayer\n",
      "\n",
      "net7 = NeuralNet(\n",
      "    layers=[\n",
      "        ('input', layers.InputLayer),\n",
      "        ('conv1', Conv2DLayer),\n",
      "        ('pool1', MaxPool2DLayer),\n",
      "        ('dropout1', layers.DropoutLayer),  # !\n",
      "        ('conv2', Conv2DLayer),\n",
      "        ('pool2', MaxPool2DLayer),\n",
      "        ('dropout2', layers.DropoutLayer),  # !\n",
      "        ('conv3', Conv2DLayer),\n",
      "        ('pool3', MaxPool2DLayer),\n",
      "        ('dropout3', layers.DropoutLayer),  # !\n",
      "        ('conv4', Conv2DLayer),###\n",
      "        ('pool4', MaxPool2DLayer),###\n",
      "        ('dropout4', layers.DropoutLayer),  # !###\n",
      "        ('conv5', Conv2DLayer),###\n",
      "        ('pool5', MaxPool2DLayer),###\n",
      "        ('dropout5', layers.DropoutLayer),  # !###\n",
      "        ('hidden6', layers.DenseLayer),\n",
      "        ('dropout6', layers.DropoutLayer),  # !\n",
      "        ('hidden7', layers.DenseLayer),\n",
      "        ('dropout7', layers.DropoutLayer),  # !\n",
      "        ('hidden8', layers.DenseLayer),\n",
      "        ('output', layers.DenseLayer),\n",
      "        ],\n",
      "    input_shape=(128, 1, 50,50),\n",
      "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_ds=(2, 2),\n",
      "    # dropout1_p=0.1, # !\n",
      "    dropout1_p=0.1,  # !\n",
      "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_ds=(2, 2),\n",
      "    # dropout2_p=0.2,  # !\n",
      "    dropout2_p=0.2,  # !\n",
      "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_ds=(2, 2),\n",
      "    # dropout3_p=0.3,  # !\n",
      "    dropout3_p=0.3,  # !\n",
      "    conv4_num_filters=256, conv4_filter_size=(2, 2), pool4_ds=(2, 2), ######\n",
      "    # dropout3_p=0.3,  # !\n",
      "    dropout4_p=0.4,  # !#########\n",
      "    conv5_num_filters=512, conv5_filter_size=(2, 2), pool5_ds=(2, 2), ######\n",
      "    # dropout3_p=0.3,  # !\n",
      "    dropout5_p=0.4,  # !#########\n",
      "    hidden6_num_units=1000,\n",
      "    # hidden4_num_units=1000,  # !\n",
      "    dropout6_p=0.5,  # !\n",
      "    hidden7_num_units=1000,\n",
      "    # hidden4_num_units=1000,  # !\n",
      "    dropout7_p=0.5,  # !\n",
      "    hidden8_num_units=1000,\n",
      "    # hidden5_num_units=1000,  # !\n",
      "    output_num_units=32, output_nonlinearity=None,\n",
      "\n",
      "    update_learning_rate=theano.shared(float32(0.03)),\n",
      "    update_momentum=theano.shared(float32(0.9)),\n",
      "\n",
      "    regression=True,\n",
      "#     batch_iterator=FlipBatchIterator(batch_size=128),\n",
      "    on_epoch_finished=[\n",
      "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
      "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
      "        EarlyStopping(patience=270),\n",
      "        ],\n",
      "    # max_epochs=3000,\n",
      "    max_epochs=10000,\n",
      "    verbose=1,\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def transform_6(X,y):\n",
      "    X = X.reshape(-1, 50,50, 1)\n",
      "    X = X.transpose(0, 3, 1, 2)\n",
      "    return X, y\n",
      "\n",
      "# X_train = X_train.reshape(-1,1,sizee,sizee)\n",
      "# X_test = X_test.reshape(-1, 1,sizee,sizee)\n",
      "# X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.setrecursionlimit(10000)\n",
      "\n",
      "X_6, y_6 = transform_6(x, y)\n",
      "%time net7.fit(X_6, y_6)\n",
      "\n",
      "import cPickle as pickle\n",
      "with open('Lasagne_12th_CNN_2_add.pickle', 'wb') as f:\n",
      "    pickle.dump(net7, f, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  InputLayer        \t(128, 1, 50, 50)    \tproduces    2500 outputs\n",
        "  Conv2DCCLayer     \t(128, 32, 48, 48)   \tproduces   73728 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 32, 24, 24)   \tproduces   18432 outputs\n",
        "  DropoutLayer      \t(128, 32, 24, 24)   \tproduces   18432 outputs\n",
        "  Conv2DCCLayer     \t(128, 64, 23, 23)   \tproduces   33856 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 64, 12, 12)   \tproduces    9216 outputs\n",
        "  DropoutLayer      \t(128, 64, 12, 12)   \tproduces    9216 outputs\n",
        "  Conv2DCCLayer     \t(128, 128, 11, 11)  \tproduces   15488 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 128, 6, 6)    \tproduces    4608 outputs\n",
        "  DropoutLayer      \t(128, 128, 6, 6)    \tproduces    4608 outputs\n",
        "  Conv2DCCLayer     \t(128, 256, 5, 5)    \tproduces    6400 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 256, 3, 3)    \tproduces    2304 outputs\n",
        "  DropoutLayer      \t(128, 256, 3, 3)    \tproduces    2304 outputs\n",
        "  Conv2DCCLayer     \t(128, 512, 2, 2)    \tproduces    2048 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 512, 1, 1)    \tproduces     512 outputs\n",
        "  DropoutLayer      \t(128, 512, 1, 1)    \tproduces     512 outputs\n",
        "  DenseLayer        \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DropoutLayer      \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DenseLayer        \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DropoutLayer      \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DenseLayer        \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DenseLayer        \t(128, 32)           \tproduces      32 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  0.030887\u001b[0m  |  \u001b[32m  0.030245\u001b[0m  |     1.021255  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.030198\u001b[0m  |  \u001b[32m  0.030241\u001b[0m  |     0.998565  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.030080\u001b[0m  |    0.030269  |     0.993731  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.029974\u001b[0m  |    0.030310  |     0.988912  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.029881\u001b[0m  |    0.030359  |     0.984240  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     6  |  \u001b[94m  0.029792\u001b[0m  |    0.030423  |     0.979252  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     7  |  \u001b[94m  0.029710\u001b[0m  |    0.030491  |     0.974392  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     8  |  \u001b[94m  0.029631\u001b[0m  |    0.030556  |     0.969723  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     9  |  \u001b[94m  0.029563\u001b[0m  |    0.030602  |     0.966077  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    10  |  \u001b[94m  0.029499\u001b[0m  |    0.030691  |     0.961162  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    11  |  \u001b[94m  0.029458\u001b[0m  |    0.030691  |     0.959839  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    12  |  \u001b[94m  0.029416\u001b[0m  |    0.030746  |     0.956747  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    13  |  \u001b[94m  0.029390\u001b[0m  |    0.030749  |     0.955811  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    14  |  \u001b[94m  0.029361\u001b[0m  |    0.030758  |     0.954567  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    15  |  \u001b[94m  0.029342\u001b[0m  |    0.030773  |     0.953474  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    16  |  \u001b[94m  0.029321\u001b[0m  |    0.030776  |     0.952729  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    17  |  \u001b[94m  0.029297\u001b[0m  |    0.030784  |     0.951689  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    18  |  \u001b[94m  0.029274\u001b[0m  |    0.030761  |     0.951659  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    19  |  \u001b[94m  0.029258\u001b[0m  |    0.030763  |     0.951073  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    20  |  \u001b[94m  0.029237\u001b[0m  |    0.030760  |     0.950494  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    21  |  \u001b[94m  0.029223\u001b[0m  |    0.030762  |     0.949952  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    22  |  \u001b[94m  0.029218\u001b[0m  |    0.030741  |     0.950429  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    23  |  \u001b[94m  0.029191\u001b[0m  |    0.030766  |     0.948816  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    24  |  \u001b[94m  0.029177\u001b[0m  |    0.030745  |     0.949000  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    25  |  \u001b[94m  0.029167\u001b[0m  |    0.030736  |     0.948937  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    26  |  \u001b[94m  0.029142\u001b[0m  |    0.030746  |     0.947814  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    27  |  \u001b[94m  0.029130\u001b[0m  |    0.030729  |     0.947988  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    28  |  \u001b[94m  0.029115\u001b[0m  |    0.030717  |     0.947847  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    29  |  \u001b[94m  0.029104\u001b[0m  |    0.030719  |     0.947416  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    30  |  \u001b[94m  0.029084\u001b[0m  |    0.030690  |     0.947672  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    31  |  \u001b[94m  0.029073\u001b[0m  |    0.030682  |     0.947566  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    32  |  \u001b[94m  0.029056\u001b[0m  |    0.030711  |     0.946101  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    33  |  \u001b[94m  0.029030\u001b[0m  |    0.030692  |     0.945828  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    34  |  \u001b[94m  0.029019\u001b[0m  |    0.030705  |     0.945109  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    35  |  \u001b[94m  0.029004\u001b[0m  |    0.030659  |     0.946002  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    36  |  \u001b[94m  0.028996\u001b[0m  |    0.030672  |     0.945376  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    37  |  \u001b[94m  0.028991\u001b[0m  |    0.030620  |     0.946801  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    38  |  \u001b[94m  0.028968\u001b[0m  |    0.030638  |     0.945498  |             |  10.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        ">"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ubuntu/src/theano/theano/sandbox/rng_mrg.py:1188: UserWarning: MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 60*256\n",
        "  nstreams = self.n_streams(size)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " /home/ubuntu/src/nolearn/nolearn/lasagne.py(146)fit()\n",
        "-> return self\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# start from here!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "## load model from Lasagne_6th_drop_change_extend.pickle extend with test1 answer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "with open('./Lasagne_10th_CNN_add.pickle', 'rb') as f:\n",
      "    net7 = pickle.load(f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.base import clone\n",
      "# model2 = clone(net7)\n",
      "# model2.load_weights_from(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "net7.train_history_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# net7.dropout1_p = 0.2\n",
      "# net7.dropout2_p = 0.3\n",
      "# net7.dropout3_p = 0.4\n",
      "net7.max_epochs = 2500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.setrecursionlimit(10000)\n",
      "\n",
      "X_6, y_6 = transform_6(x, y)\n",
      "%time net7.fit(X_6, y_6)\n",
      "\n",
      "import cPickle as pickle\n",
      "with open('Lasagne_7th_test1_0.pickle', 'wb') as f:\n",
      "    pickle.dump(net7, f, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import metrics\n",
      "\n",
      "# Xt_6, yt_6 = transform_6(X_test, y_test)\n",
      "\n",
      "# # overfit result, should use validation result\n",
      "# y_pred = net7.predict(Xt_6)\n",
      "# # print y_pred[1]\n",
      "# # np.argmax(y_pred[i]),np.argmax(y[i])\n",
      "# y_pred = np.array(map((lambda x: np.argmax(x)), y_pred))\n",
      "# yyy = np.array(map((lambda x: np.argmax(x)), yt_6))\n",
      "\n",
      "# print metrics.classification_report((yyy), (y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## load model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import cPickle as pickle\n",
      "\n",
      "# with open('./Lasagne_2nd.pickle', 'rb') as f:\n",
      "#     specialists = pickle.load(f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## submit test data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "xx_test, yy_test = load_svmlight_file(\"./phase1/new/aug_test2_50.dat\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_test = np.array(xx_test.todense()).reshape(-1,)\n",
      "# xx_train = xx_train.dtype(np.float32)\n",
      "xx_test = np.float32(xx_test)\n",
      "xx_test = xx_test.reshape(7472,2500)\n",
      "\n",
      "xx_test = xx_test.astype(np.float32)\n",
      "\n",
      "def one_hot(x,n):\n",
      "    if type(x) == list:\n",
      "            x = np.array(x)\n",
      "    x = x.flatten()\n",
      "    o_h = np.zeros((len(x),n))\n",
      "    o_h[np.arange(len(x)),x] = 1\n",
      "    return o_h\n",
      "\n",
      "yy_test = yy_test.astype(int32)    \n",
      "yy_test = one_hot(yy_test, 32)\n",
      "yy_test = yy_test.astype(np.float32)\n",
      "\n",
      "Xt, yt = transform_6(xx_test, yy_test)\n",
      "result = net7.predict(Xt)\n",
      "result = np.array(map((lambda x: np.argmax(x)), result))\n",
      "result.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_submission = pd.DataFrame( result.astype(int) ,columns=None)\n",
      "\n",
      "df_submission.to_csv('./Lasagne_12th_CNN_2_add.dat', index=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}