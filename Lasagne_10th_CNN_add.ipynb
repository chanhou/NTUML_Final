{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lasagne code try and edit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## input our data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "import scipy.linalg as sp\n",
      "from sklearn.datasets import load_svmlight_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_train, y = load_svmlight_file(\"./phase1/new/aug_train_50_big.dat\")\n",
      "# print type(xx_train)\n",
      "print xx_train.shape\n",
      "xx_train = np.array(xx_train.todense()).reshape(-1,)\n",
      "# xx_train = xx_train.dtype(np.float32)\n",
      "xx_train = np.float32(xx_train)\n",
      "xx_train = xx_train.reshape(24696,2500)\n",
      "# print xx_train.shape\n",
      "print type(xx_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 2500)\n",
        "<type 'numpy.ndarray'>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sizee = 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pylab.ion()\n",
      "# pylab.imshow(xxxx[0],cmap=cm.gray)\n",
      "x = xx_train.reshape(24696,sizee**2)\n",
      "x = x.astype(np.float32)\n",
      "\n",
      "print x.shape\n",
      "print type(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 2500)\n",
        "<type 'numpy.ndarray'>\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def one_hot(x,n):\n",
      "    if type(x) == list:\n",
      "            x = np.array(x)\n",
      "    x = x.flatten()\n",
      "    o_h = np.zeros((len(x),n))\n",
      "    o_h[np.arange(len(x)),x] = 1\n",
      "    return o_h\n",
      "\n",
      "y = y.astype(int32)    \n",
      "y = one_hot(y, 32)\n",
      "y = y.astype(np.float32)\n",
      "\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(24696, 32)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## split data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation as cv\n",
      "from sklearn import svm\n",
      "from sklearn import metrics\n",
      "from sklearn import grid_search as gs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cv.train_test_split(x, y, test_size=0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## First model of Lasagne with single hidden layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add to kfkd.py\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "\n",
      "net1 = NeuralNet(\n",
      "    layers=[  # three layers: one hidden layer\n",
      "        ('input', layers.InputLayer),\n",
      "        ('hidden', layers.DenseLayer),\n",
      "        ('output', layers.DenseLayer),\n",
      "        ],\n",
      "    # layer parameters:\n",
      "    input_shape=(128, 2500),  # 128 images per batch times 100x100 input pixels\n",
      "    hidden_num_units=300,  # number of units in hidden layer\n",
      "    output_nonlinearity=None,  # output layer uses identity function\n",
      "    output_num_units=32,  # 30 target values\n",
      "\n",
      "    # optimization method:\n",
      "    upate=nesterov_momentum,\n",
      "    update_learning_rate=0.01,\n",
      "    update_momentum=0.9,\n",
      "\n",
      "    # regression=False,  # flag to indicate we're dealing with regression problem\n",
      "    regression=True,  # flag to indicate we're dealing with regression problem\n",
      "    max_epochs=1000,  # we want to train this many epochs\n",
      "    verbose=1,\n",
      "    )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GRID K520\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time net1.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss = np.array([i[\"train_loss\"] for i in net1.train_history_])\n",
      "valid_loss = np.array([i[\"valid_loss\"] for i in net1.train_history_])\n",
      "pyplot.plot(train_loss, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(2.5e-2, 0.32e-1)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "\n",
      "# overfit result, should use validation result\n",
      "y_pred = net1.predict(X_test)\n",
      "# print y_pred[1]\n",
      "# np.argmax(y_pred[i]),np.argmax(y[i])\n",
      "y_pred = np.array(map((lambda x: np.argmax(x)), y_pred))\n",
      "yyy = np.array(map((lambda x: np.argmax(x)), y_test))\n",
      "\n",
      "print metrics.classification_report((yyy), (y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## NET 6 in the rock"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "\n",
      "def float32(k):\n",
      "    return np.cast['float32'](k)\n",
      "\n",
      "class AdjustVariable(object):\n",
      "    def __init__(self, name, start=0.03, stop=0.001):\n",
      "        self.name = name\n",
      "        self.start, self.stop = start, stop\n",
      "        self.ls = None\n",
      "\n",
      "    def __call__(self, nn, train_history):\n",
      "        if self.ls is None:\n",
      "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
      "\n",
      "        epoch = train_history[-1]['epoch']\n",
      "        new_value = float32(self.ls[epoch - 1])\n",
      "        getattr(nn, self.name).set_value(new_value)\n",
      "\n",
      "class EarlyStopping(object):\n",
      "    def __init__(self, patience=100):\n",
      "        self.patience = patience\n",
      "        self.best_valid = np.inf\n",
      "        self.best_valid_epoch = 0\n",
      "        self.best_weights = None\n",
      "\n",
      "    def __call__(self, nn, train_history):\n",
      "        current_valid = train_history[-1]['valid_loss']\n",
      "        current_epoch = train_history[-1]['epoch']\n",
      "        if current_valid < self.best_valid:\n",
      "            self.best_valid = current_valid\n",
      "            self.best_valid_epoch = current_epoch\n",
      "            self.best_weights = [w.get_value() for w in nn.get_all_params()]\n",
      "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
      "            print(\"Early stopping.\")\n",
      "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
      "                self.best_valid, self.best_valid_epoch))\n",
      "            nn.load_weights_from(self.best_weights)\n",
      "            raise StopIteration()\n",
      "        \n",
      "# use the cuda-convnet implementations of conv and max-pool layer\n",
      "Conv2DLayer = layers.cuda_convnet.Conv2DCCLayer\n",
      "MaxPool2DLayer = layers.cuda_convnet.MaxPool2DCCLayer\n",
      "\n",
      "net7 = NeuralNet(\n",
      "    layers=[\n",
      "        ('input', layers.InputLayer),\n",
      "        ('conv1', Conv2DLayer),\n",
      "        ('pool1', MaxPool2DLayer),\n",
      "        ('dropout1', layers.DropoutLayer),  # !\n",
      "        ('conv2', Conv2DLayer),\n",
      "        ('pool2', MaxPool2DLayer),\n",
      "        ('dropout2', layers.DropoutLayer),  # !\n",
      "        ('conv3', Conv2DLayer),\n",
      "        ('pool3', MaxPool2DLayer),\n",
      "        ('dropout3', layers.DropoutLayer),  # !\n",
      "        ('conv4', Conv2DLayer),###\n",
      "        ('pool4', MaxPool2DLayer),###\n",
      "        ('dropout4', layers.DropoutLayer),  # !###\n",
      "        ('hidden5', layers.DenseLayer),\n",
      "        ('dropout5', layers.DropoutLayer),  # !\n",
      "        ('hidden6', layers.DenseLayer),\n",
      "        ('output', layers.DenseLayer),\n",
      "        ],\n",
      "    input_shape=(128, 1, 50,50),\n",
      "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_ds=(2, 2),\n",
      "    # dropout1_p=0.1, # !\n",
      "    dropout1_p=0.1,  # !\n",
      "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_ds=(2, 2),\n",
      "    # dropout2_p=0.2,  # !\n",
      "    dropout2_p=0.2,  # !\n",
      "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_ds=(2, 2),\n",
      "    # dropout3_p=0.3,  # !\n",
      "    dropout3_p=0.3,  # !\n",
      "    conv4_num_filters=256, conv4_filter_size=(2, 2), pool4_ds=(2, 2), ######\n",
      "    # dropout3_p=0.3,  # !\n",
      "    dropout4_p=0.4,  # !#########\n",
      "    hidden5_num_units=1000,\n",
      "    # hidden4_num_units=1000,  # !\n",
      "    dropout5_p=0.5,  # !\n",
      "    hidden6_num_units=1000,\n",
      "    # hidden5_num_units=1000,  # !\n",
      "    output_num_units=32, output_nonlinearity=None,\n",
      "\n",
      "    update_learning_rate=theano.shared(float32(0.03)),\n",
      "    update_momentum=theano.shared(float32(0.9)),\n",
      "\n",
      "    regression=True,\n",
      "#     batch_iterator=FlipBatchIterator(batch_size=128),\n",
      "    on_epoch_finished=[\n",
      "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
      "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
      "        EarlyStopping(patience=250),\n",
      "        ],\n",
      "    # max_epochs=3000,\n",
      "    max_epochs=10000,\n",
      "    verbose=1,\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def transform_6(X,y):\n",
      "    X = X.reshape(-1, 50,50, 1)\n",
      "    X = X.transpose(0, 3, 1, 2)\n",
      "    return X, y\n",
      "\n",
      "# X_train = X_train.reshape(-1,1,sizee,sizee)\n",
      "# X_test = X_test.reshape(-1, 1,sizee,sizee)\n",
      "# X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.setrecursionlimit(10000)\n",
      "\n",
      "X_6, y_6 = transform_6(x, y)\n",
      "%time net7.fit(X_6, y_6)\n",
      "\n",
      "import cPickle as pickle\n",
      "with open('Lasagne_10th_CNN_add.pickle', 'wb') as f:\n",
      "    pickle.dump(net7, f, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  InputLayer        \t(128, 1, 50, 50)    \tproduces    2500 outputs\n",
        "  Conv2DCCLayer     \t(128, 32, 48, 48)   \tproduces   73728 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 32, 24, 24)   \tproduces   18432 outputs\n",
        "  DropoutLayer      \t(128, 32, 24, 24)   \tproduces   18432 outputs\n",
        "  Conv2DCCLayer     \t(128, 64, 23, 23)   \tproduces   33856 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 64, 12, 12)   \tproduces    9216 outputs\n",
        "  DropoutLayer      \t(128, 64, 12, 12)   \tproduces    9216 outputs\n",
        "  Conv2DCCLayer     \t(128, 128, 11, 11)  \tproduces   15488 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 128, 6, 6)    \tproduces    4608 outputs\n",
        "  DropoutLayer      \t(128, 128, 6, 6)    \tproduces    4608 outputs\n",
        "  Conv2DCCLayer     \t(128, 256, 5, 5)    \tproduces    6400 outputs\n",
        "  MaxPool2DCCLayer  \t(128, 256, 3, 3)    \tproduces    2304 outputs\n",
        "  DropoutLayer      \t(128, 256, 3, 3)    \tproduces    2304 outputs\n",
        "  DenseLayer        \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DropoutLayer      \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DenseLayer        \t(128, 1000)         \tproduces    1000 outputs\n",
        "  DenseLayer        \t(128, 32)           \tproduces      32 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  0.030963\u001b[0m  |  \u001b[32m  0.030216\u001b[0m  |     1.024724  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.030198\u001b[0m  |  \u001b[32m  0.030180\u001b[0m  |     1.000617  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.030073\u001b[0m  |  \u001b[32m  0.030155\u001b[0m  |     0.997272  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.029971\u001b[0m  |  \u001b[32m  0.030143\u001b[0m  |     0.994296  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.029866\u001b[0m  |  \u001b[32m  0.030106\u001b[0m  |     0.992043  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     6  |  \u001b[94m  0.029769\u001b[0m  |  \u001b[32m  0.030095\u001b[0m  |     0.989174  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     7  |  \u001b[94m  0.029665\u001b[0m  |  \u001b[32m  0.030055\u001b[0m  |     0.987036  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     8  |  \u001b[94m  0.029584\u001b[0m  |  \u001b[32m  0.030010\u001b[0m  |     0.985822  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     9  |  \u001b[94m  0.029507\u001b[0m  |  \u001b[32m  0.029993\u001b[0m  |     0.983778  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    10  |  \u001b[94m  0.029444\u001b[0m  |  \u001b[32m  0.029955\u001b[0m  |     0.982948  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    11  |  \u001b[94m  0.029391\u001b[0m  |  \u001b[32m  0.029934\u001b[0m  |     0.981840  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    12  |  \u001b[94m  0.029344\u001b[0m  |    0.029947  |     0.979890  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    13  |  \u001b[94m  0.029305\u001b[0m  |  \u001b[32m  0.029887\u001b[0m  |     0.980540  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    14  |  \u001b[94m  0.029253\u001b[0m  |  \u001b[32m  0.029857\u001b[0m  |     0.979775  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    15  |  \u001b[94m  0.029222\u001b[0m  |  \u001b[32m  0.029823\u001b[0m  |     0.979840  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    16  |  \u001b[94m  0.029197\u001b[0m  |  \u001b[32m  0.029786\u001b[0m  |     0.980222  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    17  |  \u001b[94m  0.029161\u001b[0m  |  \u001b[32m  0.029765\u001b[0m  |     0.979690  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    18  |  \u001b[94m  0.029123\u001b[0m  |  \u001b[32m  0.029719\u001b[0m  |     0.979945  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    19  |  \u001b[94m  0.029079\u001b[0m  |  \u001b[32m  0.029689\u001b[0m  |     0.979462  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    20  |  \u001b[94m  0.029060\u001b[0m  |  \u001b[32m  0.029641\u001b[0m  |     0.980392  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    21  |  \u001b[94m  0.029004\u001b[0m  |  \u001b[32m  0.029609\u001b[0m  |     0.979581  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    22  |  \u001b[94m  0.028986\u001b[0m  |  \u001b[32m  0.029556\u001b[0m  |     0.980719  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    23  |  \u001b[94m  0.028947\u001b[0m  |  \u001b[32m  0.029539\u001b[0m  |     0.979962  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    24  |  \u001b[94m  0.028906\u001b[0m  |  \u001b[32m  0.029467\u001b[0m  |     0.980981  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    25  |  \u001b[94m  0.028877\u001b[0m  |  \u001b[32m  0.029457\u001b[0m  |     0.980328  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    26  |  \u001b[94m  0.028841\u001b[0m  |  \u001b[32m  0.029381\u001b[0m  |     0.981621  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    27  |  \u001b[94m  0.028795\u001b[0m  |  \u001b[32m  0.029378\u001b[0m  |     0.980151  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    28  |  \u001b[94m  0.028760\u001b[0m  |  \u001b[32m  0.029324\u001b[0m  |     0.980779  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    29  |  \u001b[94m  0.028700\u001b[0m  |  \u001b[32m  0.029292\u001b[0m  |     0.979793  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    30  |  \u001b[94m  0.028667\u001b[0m  |  \u001b[32m  0.029244\u001b[0m  |     0.980254  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    31  |  \u001b[94m  0.028632\u001b[0m  |  \u001b[32m  0.029198\u001b[0m  |     0.980612  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    32  |  \u001b[94m  0.028597\u001b[0m  |  \u001b[32m  0.029156\u001b[0m  |     0.980844  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    33  |  \u001b[94m  0.028562\u001b[0m  |  \u001b[32m  0.029104\u001b[0m  |     0.981384  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    34  |  \u001b[94m  0.028520\u001b[0m  |  \u001b[32m  0.029049\u001b[0m  |     0.981780  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    35  |  \u001b[94m  0.028478\u001b[0m  |    0.029053  |     0.980211  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    36  |  \u001b[94m  0.028442\u001b[0m  |  \u001b[32m  0.028984\u001b[0m  |     0.981298  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    37  |  \u001b[94m  0.028392\u001b[0m  |  \u001b[32m  0.028976\u001b[0m  |     0.979842  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    38  |  \u001b[94m  0.028365\u001b[0m  |  \u001b[32m  0.028943\u001b[0m  |     0.980035  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    39  |  \u001b[94m  0.028330\u001b[0m  |  \u001b[32m  0.028885\u001b[0m  |     0.980793  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    40  |  \u001b[94m  0.028301\u001b[0m  |  \u001b[32m  0.028875\u001b[0m  |     0.980125  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    41  |  \u001b[94m  0.028275\u001b[0m  |  \u001b[32m  0.028825\u001b[0m  |     0.980912  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    42  |  \u001b[94m  0.028224\u001b[0m  |  \u001b[32m  0.028820\u001b[0m  |     0.979329  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    43  |  \u001b[94m  0.028218\u001b[0m  |  \u001b[32m  0.028757\u001b[0m  |     0.981270  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    44  |  \u001b[94m  0.028164\u001b[0m  |  \u001b[32m  0.028750\u001b[0m  |     0.979619  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    45  |  \u001b[94m  0.028158\u001b[0m  |  \u001b[32m  0.028714\u001b[0m  |     0.980664  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    46  |  \u001b[94m  0.028138\u001b[0m  |  \u001b[32m  0.028703\u001b[0m  |     0.980313  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    47  |  \u001b[94m  0.028088\u001b[0m  |  \u001b[32m  0.028667\u001b[0m  |     0.979806  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    48  |  \u001b[94m  0.028064\u001b[0m  |  \u001b[32m  0.028604\u001b[0m  |     0.981146  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    49  |  \u001b[94m  0.028035\u001b[0m  |    0.028616  |     0.979684  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    50  |  \u001b[94m  0.027994\u001b[0m  |  \u001b[32m  0.028571\u001b[0m  |     0.979803  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    51  |  \u001b[94m  0.027969\u001b[0m  |  \u001b[32m  0.028560\u001b[0m  |     0.979291  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    52  |  \u001b[94m  0.027939\u001b[0m  |  \u001b[32m  0.028531\u001b[0m  |     0.979246  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    53  |  \u001b[94m  0.027898\u001b[0m  |  \u001b[32m  0.028495\u001b[0m  |     0.979034  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    54  |  \u001b[94m  0.027875\u001b[0m  |  \u001b[32m  0.028478\u001b[0m  |     0.978807  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    55  |  \u001b[94m  0.027847\u001b[0m  |  \u001b[32m  0.028426\u001b[0m  |     0.979614  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    56  |  \u001b[94m  0.027807\u001b[0m  |  \u001b[32m  0.028424\u001b[0m  |     0.978315  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    57  |  \u001b[94m  0.027777\u001b[0m  |  \u001b[32m  0.028381\u001b[0m  |     0.978704  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    58  |  \u001b[94m  0.027738\u001b[0m  |  \u001b[32m  0.028342\u001b[0m  |     0.978678  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    59  |  \u001b[94m  0.027698\u001b[0m  |  \u001b[32m  0.028322\u001b[0m  |     0.977966  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    60  |  \u001b[94m  0.027665\u001b[0m  |  \u001b[32m  0.028303\u001b[0m  |     0.977449  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    61  |  \u001b[94m  0.027631\u001b[0m  |  \u001b[32m  0.028243\u001b[0m  |     0.978330  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    62  |  \u001b[94m  0.027612\u001b[0m  |  \u001b[32m  0.028218\u001b[0m  |     0.978530  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    63  |  \u001b[94m  0.027564\u001b[0m  |  \u001b[32m  0.028150\u001b[0m  |     0.979156  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    64  |  \u001b[94m  0.027531\u001b[0m  |  \u001b[32m  0.028094\u001b[0m  |     0.979975  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    65  |  \u001b[94m  0.027492\u001b[0m  |  \u001b[32m  0.028070\u001b[0m  |     0.979425  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    66  |  \u001b[94m  0.027442\u001b[0m  |  \u001b[32m  0.028050\u001b[0m  |     0.978331  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    67  |  \u001b[94m  0.027419\u001b[0m  |  \u001b[32m  0.027984\u001b[0m  |     0.979797  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    68  |  \u001b[94m  0.027357\u001b[0m  |  \u001b[32m  0.027959\u001b[0m  |     0.978475  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    69  |  \u001b[94m  0.027342\u001b[0m  |  \u001b[32m  0.027892\u001b[0m  |     0.980278  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    70  |  \u001b[94m  0.027274\u001b[0m  |  \u001b[32m  0.027874\u001b[0m  |     0.978477  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    71  |  \u001b[94m  0.027259\u001b[0m  |  \u001b[32m  0.027818\u001b[0m  |     0.979908  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    72  |  \u001b[94m  0.027205\u001b[0m  |  \u001b[32m  0.027780\u001b[0m  |     0.979305  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    73  |  \u001b[94m  0.027149\u001b[0m  |  \u001b[32m  0.027718\u001b[0m  |     0.979486  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    74  |  \u001b[94m  0.027127\u001b[0m  |    0.027732  |     0.978161  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    75  |  \u001b[94m  0.027083\u001b[0m  |  \u001b[32m  0.027657\u001b[0m  |     0.979243  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    76  |  \u001b[94m  0.027041\u001b[0m  |  \u001b[32m  0.027601\u001b[0m  |     0.979724  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    77  |  \u001b[94m  0.026998\u001b[0m  |  \u001b[32m  0.027518\u001b[0m  |     0.981101  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    78  |  \u001b[94m  0.026943\u001b[0m  |  \u001b[32m  0.027512\u001b[0m  |     0.979346  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    79  |  \u001b[94m  0.026908\u001b[0m  |  \u001b[32m  0.027436\u001b[0m  |     0.980748  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    80  |  \u001b[94m  0.026864\u001b[0m  |  \u001b[32m  0.027388\u001b[0m  |     0.980874  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    81  |  \u001b[94m  0.026831\u001b[0m  |  \u001b[32m  0.027360\u001b[0m  |     0.980660  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    82  |  \u001b[94m  0.026786\u001b[0m  |  \u001b[32m  0.027257\u001b[0m  |     0.982707  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    83  |  \u001b[94m  0.026727\u001b[0m  |  \u001b[32m  0.027248\u001b[0m  |     0.980884  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    84  |  \u001b[94m  0.026698\u001b[0m  |  \u001b[32m  0.027191\u001b[0m  |     0.981883  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    85  |  \u001b[94m  0.026644\u001b[0m  |  \u001b[32m  0.027131\u001b[0m  |     0.982063  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    86  |  \u001b[94m  0.026583\u001b[0m  |  \u001b[32m  0.027043\u001b[0m  |     0.982987  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    87  |  \u001b[94m  0.026543\u001b[0m  |  \u001b[32m  0.027021\u001b[0m  |     0.982297  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    88  |  \u001b[94m  0.026515\u001b[0m  |  \u001b[32m  0.026973\u001b[0m  |     0.983003  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    89  |  \u001b[94m  0.026491\u001b[0m  |  \u001b[32m  0.026915\u001b[0m  |     0.984259  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    90  |  \u001b[94m  0.026430\u001b[0m  |  \u001b[32m  0.026835\u001b[0m  |     0.984897  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    91  |  \u001b[94m  0.026381\u001b[0m  |  \u001b[32m  0.026821\u001b[0m  |     0.983612  |             |  9.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    92  |  \u001b[94m  0.026338\u001b[0m  |  \u001b[32m  0.026724\u001b[0m  |     0.985555  |             |  9.2s"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# start from here!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "## load model from Lasagne_6th_drop_change_extend.pickle extend with test1 answer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "with open('./Lasagne_5th_try_drop_change.pickle', 'rb') as f:\n",
      "    net7 = pickle.load(f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn.base import clone\n",
      "# model2 = clone(net7)\n",
      "# model2.load_weights_from(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# net7.dropout1_p = 0.2\n",
      "# net7.dropout2_p = 0.3\n",
      "# net7.dropout3_p = 0.4\n",
      "net7.max_epochs = 2500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.setrecursionlimit(10000)\n",
      "\n",
      "X_6, y_6 = transform_6(x, y)\n",
      "%time net7.fit(X_6, y_6)\n",
      "\n",
      "import cPickle as pickle\n",
      "with open('Lasagne_7th_test1_0.pickle', 'wb') as f:\n",
      "    pickle.dump(net7, f, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_loss_6 = np.array([i[\"train_loss\"] for i in net7.train_history_])\n",
      "valid_loss_6 = np.array([i[\"valid_loss\"] for i in net7.train_history_])\n",
      "pyplot.plot(train_loss_6, linewidth=3, label=\"train\")\n",
      "pyplot.plot(valid_loss_6, linewidth=3, label=\"valid\")\n",
      "pyplot.grid()\n",
      "pyplot.legend()\n",
      "pyplot.xlabel(\"epoch\")\n",
      "pyplot.ylabel(\"loss\")\n",
      "pyplot.ylim(0.1e-2, 3.2e-2)\n",
      "# pyplot.yscale(\"log\")\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from sklearn import metrics\n",
      "\n",
      "# Xt_6, yt_6 = transform_6(X_test, y_test)\n",
      "\n",
      "# # overfit result, should use validation result\n",
      "# y_pred = net7.predict(Xt_6)\n",
      "# # print y_pred[1]\n",
      "# # np.argmax(y_pred[i]),np.argmax(y[i])\n",
      "# y_pred = np.array(map((lambda x: np.argmax(x)), y_pred))\n",
      "# yyy = np.array(map((lambda x: np.argmax(x)), yt_6))\n",
      "\n",
      "# print metrics.classification_report((yyy), (y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## load model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import cPickle as pickle\n",
      "\n",
      "# with open('./Lasagne_2nd.pickle', 'rb') as f:\n",
      "#     specialists = pickle.load(f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## submit test data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "xx_test, yy_test = load_svmlight_file(\"./phase1/new/aug_test2_50.dat\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx_test = np.array(xx_test.todense()).reshape(-1,)\n",
      "# xx_train = xx_train.dtype(np.float32)\n",
      "xx_test = np.float32(xx_test)\n",
      "xx_test = xx_test.reshape(7472,2500)\n",
      "\n",
      "xx_test = xx_test.astype(np.float32)\n",
      "\n",
      "def one_hot(x,n):\n",
      "    if type(x) == list:\n",
      "            x = np.array(x)\n",
      "    x = x.flatten()\n",
      "    o_h = np.zeros((len(x),n))\n",
      "    o_h[np.arange(len(x)),x] = 1\n",
      "    return o_h\n",
      "\n",
      "yy_test = yy_test.astype(int32)    \n",
      "yy_test = one_hot(yy_test, 32)\n",
      "yy_test = yy_test.astype(np.float32)\n",
      "\n",
      "Xt, yt = transform_6(xx_test, yy_test)\n",
      "result = net7.predict(Xt)\n",
      "result = np.array(map((lambda x: np.argmax(x)), result))\n",
      "result.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_submission = pd.DataFrame( result.astype(int) ,columns=None)\n",
      "\n",
      "df_submission.to_csv('./Lasagne_10th_CNN_add.dat', index=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}